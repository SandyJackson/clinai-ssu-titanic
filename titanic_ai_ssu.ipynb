{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting survival on the Titanic:\n",
    "# An introduction to Machine Learning with Python\n",
    "*By Alexander I.R Jackson, University of Southampton*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will work with data about passengers on the RMS Titanic's maiden voyage; which famously ended in disaster.\n",
    "\n",
    "We'll use python and machine learning libraries to try and understand and predict survival on this fateful voyage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages\n",
    "Here we will load all the packages needed for our analysis. You can modify this list and add to it if you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data\n",
    "We will use Pandas to import the data from 'titanic.csv' file and store it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data from GitHub\n",
    "! mkdir data\n",
    "! curl https://github.com/SandyJackson/clinai-ssu-titanic/blob/95a23e83e7dbe3b4b09f6594286019ae62b86e18/data/titanic.csv --output data/titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line reads the data and stores the information in the titanic_df variable\n",
    "titanic_df = pd.read_csv('data/titanic.csv')\n",
    "titanic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Getting an overview\n",
    "Pandas DataFrames have a number of useful methods to explore DataFrames. \n",
    "We use these by writing the variable name (`titanic_df`) then a dot (`.`) and then the method like `head(x)` - which shows the x first rows.\n",
    "Some other methods you can use include:\n",
    "* `tail()`\n",
    "* `sample()`\n",
    "* `shape` - notice this isn't actually a method, there is no () instead it's an attribute or property.\n",
    "* `info()`\n",
    "* `describe()`\n",
    "\n",
    "Try these out and see if you can work out what they do. We've done an example with `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head\n",
    "titanic_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data understanding\n",
    "Some of these columns don't make a lot of sense! Luckily we've done the hard work and found what the different random numbers and letters mean. In the real world this can be much harder\n",
    "```markdown\n",
    "Variable    Definition      Key\n",
    "\n",
    "survival    Survival        0 = No, 1 = Yes\n",
    "pclass      Ticket class    1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "name        Passenger Name\n",
    "sex         Sex\n",
    "Age         Age in years\n",
    "sibsp       # of siblings / spouses aboard the Titanic\n",
    "parch       # of parents / children aboard the Titanic\n",
    "ticket      Ticket number\n",
    "fare        Passenger fare\n",
    "cabin       Cabin number\n",
    "embarked    Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a column\n",
    "If you just want to select one column there are a few ways.\n",
    "The simplest is using square brackets `[]` and the columns name in quotation marks `''` or `\"\"`\n",
    "\n",
    "for example:\n",
    "`titanic_df['name']`\n",
    "\n",
    "Try this out below!\n",
    "\n",
    "P.S. If you are really getting into this then it's worth reading [the Pandas documentation on this](https://pandas.pydata.org/docs/user_guide/indexing.html) as there are different ways to select and index data, which should be used at different times!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column by name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting some insights\n",
    "\n",
    "Now you can select a column lets try and understand something about the data...\n",
    "\n",
    "These methods can be used on individual columns (called Series in Pandas) and can be useful in lots of ways\n",
    "\n",
    "* `mean()`\n",
    "* `median()`\n",
    "* `min()`, `max()`\n",
    "* `value_counts()`\n",
    "\n",
    "Try some out below. Remember it's hard to calculate mean on a name! (or any string) and `value_counts()` probably isn't the best way to summarise the fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where did most passengers board the Titanic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is a bit more complicated... can you figure it out?\n",
    "\n",
    "titanic_df.groupby('pclass').agg(mean_fare=('fare', 'mean'),\n",
    "                                 mean_age=('age', 'mean'),\n",
    "                                 count=('pclass', 'count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy the data\n",
    "\n",
    "This is probably the most time consuming and most important part of machine learning and data science. Don't worry though... not today!\n",
    "\n",
    "The Titanic dataset is already pretty clean and well structured, but there are still a few things to think about\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the important columns\n",
    "\n",
    "Not all the columns will be useful for predicting who will survive. Some columns are best left out of the modelling stage.\n",
    "\n",
    "Can you think which ones and get rid of them using the code below?\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>ðŸ’¡ Hint</summary>\n",
    "\n",
    "Anything that is unique to each individual is unlikely to be useful in predicting outcome (unless you do some additional clever analysis). There are two 'unique' columns\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below will 'drop' the columns that you specify.\n",
    "# Which columns should we leave out? (Remember if you want to drop more than one its a list of strings)\n",
    "# Notice we save the output to a new DataFrame called titanic_df_clean, we'll use this going forward\n",
    "\n",
    "titanic_df_clean = titanic_df.drop(columns=['COL NAME HERE'], axis=1)\n",
    "\n",
    "# Now print that new DataFrame out. Does it look right?\n",
    "titanic_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cabin Column\n",
    "\n",
    "Let's have a close look at this column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random sample of 10 rows from the DataFrame\n",
    "titanic_df['cabin'].sample(10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be a lot of NaN (missing values). Let's try and work out why.\n",
    "\n",
    "* What does the column mean?\n",
    "* Why are there so many missing values?\n",
    "* What could we do to make it useful?\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>ðŸ’¡ Hint</summary>\n",
    "\n",
    "Maybe only passengers who could afford a cabin will have one? Or maybe the data are just poor?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll try one possible approach to make the cabin data more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a blank list to store our new columns data in\n",
    "cabin_bool = []\n",
    "\n",
    "# Now a for loop goes through every row in the 'cabin' column\n",
    "# Can you work out what it does?\n",
    "for cabin in titanic_df['cabin']:\n",
    "    if pd.isna(cabin):\n",
    "        cabin_bool.append(False)\n",
    "    else:\n",
    "        cabin_bool.append(True)\n",
    "\n",
    "# Print out the first 10 values of the new list to see what it does\n",
    "cabin_bool[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary markdown='span'>ðŸ’¡ Hint (if the loop doesn't make sense)</summary>\n",
    "the pd.isna() function checks if a value is missing (NaN)\n",
    "</details>\n",
    "\n",
    "Remember in programming there are often lots of ways to achieve the same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The line below does exactly the same thing but in one line\n",
    "\n",
    "cabin_bool_quick = [True if not pd.isna(cabin) else False for cabin in titanic_df_clean['cabin']]\n",
    "\n",
    "# Lets check they are the same (should print True if they are the same)\n",
    "cabin_bool == cabin_bool_quick\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new 'cabin_bool' column in the DataFrame\n",
    "titanic_df_clean['cabin_bool'] = cabin_bool\n",
    "\n",
    "# Drop the old cabin column\n",
    "titanic_df_clean.drop(columns=['cabin'], axis=1, inplace=True)\n",
    "\n",
    "# Check the new DataFrame\n",
    "titanic_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The missing values\n",
    "We know our data have some missing values - you might have noticed in the early exploration (`.info()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But just how many missing values are there?\n",
    "titanic_df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`age` seems to have the most missing values (>250)\n",
    "\n",
    "**What are our options?**\n",
    "* Should we get rid of age completely?\n",
    "    * Remember that 'women and children go first' was important on the titanic, so age might be important\n",
    "* Should we just get rid of the rows where age is missing?\n",
    "* What else could we do?\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>ðŸ’¡ Hint</summary>\n",
    "We could put a value in or 'impute'.\n",
    "This could be the mean, median or any other value we like</details>\n",
    "\n",
    "**What about the other few missing values in other colums?**\n",
    "\n",
    "To keep things simple, we could just select only columns with all the data complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line will drop all rows with missing values\n",
    "titanic_df_clean.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows did we lose?\n",
    "titanic_df_clean.shape[0] - titanic_df_clean.dropna().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just use the rows without missing values for now!\n",
    "titanic_df_clean = titanic_df_clean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start modelling!\n",
    "\n",
    "We'll now go on and try some simple statistical modelling before building up to more complex machine learning.\n",
    "\n",
    "Remember our goal is to predict which passengers will survive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Splitting the data\n",
    "\n",
    "But first up we need a training set and a test set. We also need our X (inputs) and our y (outcome) separate.\n",
    "\n",
    "Luckily there are packages that will do a lot of the legwork for you. Below we use the `train_test_split` function from sklearn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
    "\n",
    "You'll still need to select the correct y (the outcome we are interested in)\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>ðŸ’¡ Hint </summary>\n",
    "Remember we want to predict survival and the colum is called survived. So try selecting that column using the square brackets []\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select our X\n",
    "X = titanic_df_clean.drop(columns='survived', axis=1)\n",
    "\n",
    "# Select our y\n",
    "y = # YOUR ANSWER HERE\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try comparing the size of the training and testing sets (remember the shape attribute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logisitic Regression\n",
    "This will be our most simple model. You'll see Logistic regression used in lots of medical publications - its really common!\n",
    "Some people wouldn't even regard it as 'Machine Learning' but all the same basic principles apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a model object that we can train with our data\n",
    "model = LogisticRegression(penalty='none')\n",
    "\n",
    "# This line will train and test our model (using only the training data)\n",
    "cross_validate(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Failure**\n",
    "\n",
    "But can you work out why?\n",
    "\n",
    "The error message says:\n",
    "`ValueError: could not convert string to float: 'male'`\n",
    "\n",
    "Remember computers can only understand numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous vs Categorical\n",
    "First off we need to work out which columns are categorical and which are continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of each type of column\n",
    "categorical_columns = ['sex', 'embarked', 'cabin_bool']\n",
    "numerical_columns = ['pclass', 'age', 'sibsp', 'parch', 'fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to model using only the numerical columns\n",
    "model = LogisticRegression(penalty=None, max_iter=5000)\n",
    "cross_validate(model, X_train[numerical_columns], y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Data\n",
    "\n",
    "Some of those categorical variables may be very helpful in predicting survival.\n",
    "\n",
    "So let's take all of our categorical data and encode it into a format that our model can understand.\n",
    "\n",
    "First off which variables are categorical? Put them into the list below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object to encode the categorical data; we'll use sklearn's OneHotEncoder (don't worry too much about specifics)\n",
    "ohe = OneHotEncoder(drop='if_binary', sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit the encoder to the training data (i.e. learn the categories)\n",
    "ohe.fit(X_train[categorical_columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we transform those cataegorical columns into numbers\n",
    "encoded_cols = ohe.transform(X_train[categorical_columns])\n",
    "\n",
    "# Print the values out\n",
    "print(f\"The encoded values have {encoded_cols.shape[0]} rows and {encoded_cols.shape[1]} columns\")\n",
    "print('But what do they represent?')\n",
    "encoded_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't know what they mean. Luckily, we can ask the encoder to tell us!\n",
    "ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets put those together and make a new dataframe with encoded values\n",
    "# Lets start by taking just the numerical columns\n",
    "X_train_encoded = X_train[numerical_columns].copy()\n",
    "# Let's see what we get\n",
    "X_train_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets add the encoded categorical columns, we get the names from the encoder and then the data from the unnamed array above\n",
    "X_train_encoded[ohe.get_feature_names_out()] = encoded_cols\n",
    "\n",
    "# Lets print it out and see what it looks like\n",
    "X_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look back at the data before 'encoding' and see if it makes sense.\n",
    "# Compare the two (new is above and old is below) and see if you can understand what is happening with encoding\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets see if all our work has paid off!\n",
    "# We'll try out the model on our training data and see how it performs\n",
    "cross_validate(model, X_train_encoded, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model\n",
    "\n",
    "OK so we have a model with all our data that seems to work. Shall we test it the right way?\n",
    "\n",
    "* What is the right way?\n",
    "* Why is using the `test` data only for testing important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll train the model using only the training data using .fit\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "# Lets see how the model performs and save the score\n",
    "train_score = model.score(X_train_encoded, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the test data\n",
    "Remember all that work to encode the categorical variables?\n",
    "We have to do it again, but this time it's much quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if you can work out what the code below does\n",
    "X_test_encoded = X_test[numerical_columns].copy()\n",
    "X_test_encoded[ohe.get_feature_names_out()] = ohe.transform(X_test[categorical_columns])\n",
    "print(\"Is it the same format as the training data?\")\n",
    "X_test_encoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's get the score!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the same model, but this time we score it on the test data\n",
    "test_score = model.score(X_test_encoded, y_test)\n",
    "\n",
    "print(f\"Train score: {train_score}\")\n",
    "print(f\"Test score: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Does the model perform better or worse?\n",
    "* Why might that be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Model Types (Optional)\n",
    "\n",
    "Logisitc regression is pretty common - it's also quite simple. But for this task it still performs pretty well.\n",
    "\n",
    "However, there are lots of other machine learning models you can play about with. Below we will try some out.\n",
    "\n",
    "But first more data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the numerical columns\n",
    "Basic logistic regression works with any old numbers.\n",
    "Unfortunately, most machine learning methods (even more advanced logistic regression) require something called scaling\n",
    "\n",
    "Basically all the different variables need to be a similar scale or the model might incorrectly think the biggest number is the most important!\n",
    "\n",
    "* What would that mean for the Titanic data we already have?\n",
    "\n",
    "OK let's scale these numbers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The scaler is a bit like the encoder, but it scales the numerical data (this one scales between 0 and 1)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# We fit and transform just like before\n",
    "scaler.fit(X_train[numerical_columns])\n",
    "scaled_data = scaler.transform(X_train[numerical_columns])\n",
    "\n",
    "# Now we put it all together\n",
    "X_train_scaled = pd.DataFrame(scaled_data, columns=numerical_columns)\n",
    "X_train_scaled[ohe.get_feature_names_out()] = encoded_cols\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do the same for the test data\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test[numerical_columns]), columns=numerical_columns)\n",
    "X_test_scaled[ohe.get_feature_names_out()] = ohe.transform(X_test[categorical_columns])\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying some models\n",
    "We'll try out 3 different models and see how they perform\n",
    "\n",
    "These are working on default settings and may perform well, they may perform poorly and they might make some incorrect assumptions\n",
    "\n",
    "**This is not best practice but we are showing you how quickly you can try out different models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A multinomial naive bayes model\n",
    "bayes_model = MultinomialNB()\n",
    "cross_validate(bayes_model, X_train_scaled, y_train, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A support vector classifier\n",
    "svm_model = SVC()\n",
    "cross_validate(svm_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A gradient boosting classifier\n",
    "gb_model = GradientBoostingClassifier()\n",
    "cross_validate(gb_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning\n",
    "The support vector classifier and gradient boosting classifer both seem to perform quite well; but the gradient boosting is performing slightly better.\n",
    "\n",
    "Let's see if we can improve it with some tuning\n",
    "\n",
    "We'll start by getting some baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "gb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Calculate the training and testing scores, and print them below\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"Training score: {gb_model.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing score: {gb_model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it performs very well on the training data but less well on the testing.\n",
    "* What is this a sign of?\n",
    "<details>\n",
    "    <summary markdown='span'>ðŸ’¡ Hint</summary>\n",
    "Overfitting\n",
    "</details>\n",
    "\n",
    "So let's see if we can improve test performance with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid Search**\n",
    "\n",
    "We'll do something called a `grid search`. Here we give a list of different parameters of the model we can adjust to a function.\n",
    "\n",
    "The function then tries every possible combination on the training data using something called cross-validation.\n",
    "\n",
    "Once it's finished it can tell you the combination that performs best.\n",
    "\n",
    "For more information about the parameters you can look at the [Gradient Boosting Classifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)\n",
    "\n",
    "To learn more about hyperparameter tuning and different kinds of searches (grid, random etc.) look at [this sklearn guide](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary of parameters\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "                'max_depth': [3, 5, 7],\n",
    "                'learning_rate': [0.1, 0.01, 0.001]}\n",
    "\n",
    "# Setup the grid search with our model, the parameter grid and a few other variables\n",
    "grid_search = GridSearchCV(\n",
    "    estimator= gb_model, \n",
    "    param_grid = param_grid, \n",
    "    cv=5, scoring='accuracy')\n",
    "\n",
    "# Now we run the grid search. This will take a while!\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have done the .fit we can see the best parameters\n",
    "print(grid_search.best_params_)\n",
    "# And the best score (notice this time we make it a percentage for readability!)\n",
    "print(f\"Grid Search best score: {round(grid_search.best_score_*100, 2)}% accurate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we instantiate a new model with the best parameters\n",
    "gb_model_optimised = GradientBoostingClassifier(**grid_search.best_params_)\n",
    "# Lets check if it has the 'best parameters'\n",
    "gb_model_optimised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train the new model on our training data\n",
    "gb_model_optimised.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Finally we can print the training and testing scores\n",
    "print(\"Gradient Boosting:\")\n",
    "print(f\"Training score: {gb_model_optimised.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing score: {gb_model_optimised.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin\n",
    "Well done you've reached the end.\n",
    "\n",
    "There is lot's more we can talk about or do and load more to learn.\n",
    "\n",
    "You could try optimising some different models; or maybe you want to try some different approaches to the data.\n",
    "* Should `Pclass` be ordinal rather than numeric?\n",
    "* Could we impute the 250 missing `age` to make our dataset bigger?\n",
    "* Could we drop some of the variables that aren't making any difference?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airj_cipher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
